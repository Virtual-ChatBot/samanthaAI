import React, {useEffect, useState} from "react";

//CSS
import '../styles/mikeBot.css';

// URL
const mikeOff = 'https://beemil.site/images/samantha/mikeOff.gif';
const mikeOn = 'https://beemil.site/images/samantha/mikeOn.gif';

function MikeBot({ STT })  {

    const [stream, setStream] = useState();

    const [media, setMedia] = useState();

    const [recognition, setOnRecognition] = useState(true);

    const [source, setSource] = useState();

    const [analyser, setAnalyser] = useState();

    const [audioUrl, setAudioUrl] = useState();

    function startRecording(){

        // ìŒì›ì •ë³´ë¥¼ ë‹´ì€ ë…¸ë“œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ìŒì›ì„ ì‹¤í–‰ë˜ëŠ” ë””ì½”ë”© ì‹œí‚¤ëŠ” ì¼ì„ í•œë‹¤
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

        // ìžë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ìŒì›ì˜ ì§„í–‰ìƒíƒœì— ì§ì ‘ì ‘ê·¼ì— ì‚¬ìš©ëœë‹¤.
        const analyser = audioCtx.createScriptProcessor(0, 1, 1);

        setAnalyser(analyser);

        function makeSound(stream) {
          // ë‚´ ì»´í“¨í„°ì˜ ë§ˆì´í¬ë‚˜ ë‹¤ë¥¸ ì†ŒìŠ¤ë¥¼ í†µí•´ ë°œìƒí•œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì˜ ì •ë³´ë¥¼ ë³´ì—¬ì¤€ë‹¤.
          const source = audioCtx.createMediaStreamSource(stream);
          setSource(source);
          source.connect(analyser);
          analyser.connect(audioCtx.destination);
        }

        // ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œ íšë“
        console.warn('getUserMedia will be allowed.');
        const constraints = { audio: true };
        navigator.mediaDevices.getUserMedia(constraints)
            .then((stream) => {
                handleMediaStream(stream);
            })
            .catch((error) => {
                console.error('Error accessing microphone:', error);
            });

        function handleMediaStream(stream) {
            const mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.start();
            setStream(stream);
            setMedia(mediaRecorder);
            makeSound(stream);

            analyser.onaudioprocess = function (e) {
                if (e.playbackTime > 10) {
                    stream.getAudioTracks().forEach(function (track) {
                        track.stop();
                    });
                    mediaRecorder.stop();
                    analyser.disconnect();
                    audioCtx.createMediaStreamSource(stream).disconnect();

                    mediaRecorder.ondataavailable = function (e) {
                        setAudioUrl(e.data);
                        setOnRecognition(true);
                    };
                } else {
                    setOnRecognition(false);
                }
            }
        }
    }

    // ì‚¬ìš©ìžê°€ ìŒì„± ë…¹ìŒì„ ì¤‘ì§€ í–ˆì„ ë•Œ
    // eslint-disable-next-line react-hooks/exhaustive-deps
    function stopRecording() {

        // dataAvailable ì´ë²¤íŠ¸ë¡œ Blob ë°ì´í„°ì— ëŒ€í•œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìžˆìŒ
        media.ondataavailable = function (e) {

            setAudioUrl(e.data);
            setOnRecognition(true);

            //ë§ˆì´í¬ì— ìž…ë ¥ëœ ì‚¬ëžŒì˜ ìŒì„±ì„ ë°”ì´ë„ˆë¦¬ ìŒì„±íŒŒì¼ë¡œ ë³€í™˜ ì‹œìž‘
            const formData= new FormData();
            formData.append("audio", new Blob([e.data], { type: "audio/mpeg" }));

            // ë„¤ì´ë²„ STT OPEN API ðŸ˜€ðŸ˜€ðŸ˜€
            fetch('https://beemil.site/bot/stt', {

              method: "POST",
              body: formData

            }).then((response) => response.json())
            .then((data) => {

              console.log(data)
              STT(data.text);

            }).catch((error) => {

              console.log(error.message)
            })
        };

        // ëª¨ë“  íŠ¸ëž™ì—ì„œ stop()ì„ í˜¸ì¶œí•´ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì •ì§€
        stream.getAudioTracks().forEach(function (track) {

            track.stop();
        });

        // ë¯¸ë””ì–´ ìº¡ì²˜ ì¤‘ì§€
        media.stop();

        // ë©”ì„œë“œê°€ í˜¸ì¶œ ëœ ë…¸ë“œ ì—°ê²° í•´ì œ
        analyser.disconnect();
        source.disconnect();

        // ìƒì„±ëœ ìŒì„± íŒŒì¼ ì •ë³´ ì¶œë ¥
        const sound = new File([audioUrl], "soundBlob", {

            lastModified: new Date().getTime(),
            type: "audio",
        });
        console.log(sound);
    }

    useEffect(() => {

        if (!recognition) {

            const timer = setTimeout(stopRecording, 3000); // 3ì´ˆ (5000ms)
            return () => clearTimeout(timer);
        }
    }, [recognition, stopRecording]);

    return (

        <div className="voiceButton">
            {recognition ? (
                <img className="mikeButton" src={mikeOff} alt="Microphone Off" onClick={startRecording} />
            ) : (
                <img className="mikeButton" src={mikeOn} alt="Microphone On" onClick={stopRecording} />
            )}
        </div>
    );
}
export default MikeBot;